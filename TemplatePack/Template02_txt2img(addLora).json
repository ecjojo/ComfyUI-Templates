{
  "last_node_id": 15,
  "last_link_id": 16,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1650,
        300
      ],
      "size": {
        "0": 140,
        "1": 60
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            9
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        1000,
        600
      ],
      "size": {
        "0": 220,
        "1": 106
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            2
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        1
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        1300,
        300
      ],
      "size": {
        "0": 300,
        "1": 474
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 14
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        366897252908732,
        "randomize",
        20,
        8,
        "euler",
        "normal",
        1
      ]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        31,
        293
      ],
      "size": {
        "0": 328.5366516113281,
        "1": 98
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            12
          ],
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            13
          ],
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            11
          ],
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "dreamshaper_8.safetensors"
      ]
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1840,
        300
      ],
      "size": {
        "0": 410,
        "1": 460
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "properties": {},
      "widgets_values": [
        "%date:yyyy-MM-dd%/Template02"
      ]
    },
    {
      "id": 15,
      "type": "LoraLoader",
      "pos": [
        430,
        290
      ],
      "size": {
        "0": 315,
        "1": 126
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 12
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            14
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            15,
            16
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "EC.safetensors",
        0.7000000000000001,
        0.7000000000000001
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        850,
        160
      ],
      "size": {
        "0": 370,
        "1": 160
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 15
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            4
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Positive)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "a photo of an cute girl wearing a white dress, bedroom,\n\nsolo, focus, brown long hair, bangs, \n\ncinematic, dramatic lighting, high resolution, detailed, 4k, \nlook at viewer, closeup, raw photo, best lighting, dynamic pose, best quality, ultra high res, photorealitic"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        850,
        380
      ],
      "size": {
        "0": 370,
        "1": 160
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 16
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Negative)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry, illustration, toy, clay, low quality, flag, nasa, mission patch, logo,"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 11,
      "type": "Note",
      "pos": [
        -358,
        292
      ],
      "size": {
        "0": 318.1748352050781,
        "1": 243.10028076171875
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "ComfyUI Workflow Templates 02\n\nText 2 Img (+Lora)\n\n⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯\nPatreon | ComfyUI Guide & Workflow\nhttps://www.patreon.com/ecjojo\n\nFollow me on Twitter\nhttps://twitter.com/ecjojo_ai\n\nJoin my Discord Community\nhttps://discord.gg/mwVwW8j7Gy"
      ],
      "color": "#233",
      "bgcolor": "#355"
    }
  ],
  "links": [
    [
      2,
      5,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      11,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      12,
      4,
      0,
      15,
      0,
      "MODEL"
    ],
    [
      13,
      4,
      1,
      15,
      1,
      "CLIP"
    ],
    [
      14,
      15,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      15,
      15,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      16,
      15,
      1,
      7,
      0,
      "CLIP"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}