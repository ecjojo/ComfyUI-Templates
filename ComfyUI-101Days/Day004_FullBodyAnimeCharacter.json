{
  "last_node_id": 77,
  "last_link_id": 135,
  "nodes": [
    {
      "id": 23,
      "type": "VAEDecode",
      "pos": [
        2012.4170934916754,
        348.982064225845
      ],
      "size": {
        "0": 302.1603698730469,
        "1": 74.05064392089844
      },
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 30
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 32
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            111
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 5,
      "type": "CLIPVisionLoader",
      "pos": [
        1576.946789916992,
        -155.34301754760736
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            124
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "model.safetensors"
      ]
    },
    {
      "id": 2,
      "type": "CheckpointLoaderSimple",
      "pos": [
        348.4093948697726,
        -138.06833325633175
      ],
      "size": [
        365.01576770568903,
        104.6283113946485
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            125,
            129
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            13,
            45,
            114
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            32,
            115
          ],
          "shape": 3,
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "meinamix_meinaV11.safetensors"
      ]
    },
    {
      "id": 26,
      "type": "EmptyLatentImage",
      "pos": [
        2002.6770726704478,
        -144.9975146663673
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            34
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        1024,
        1
      ]
    },
    {
      "id": 18,
      "type": "KSampler",
      "pos": [
        2012.4170934916754,
        25.98206422584497
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 48
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 36
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 22
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 34,
          "slot_index": 3
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            30
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        124780005383971,
        "randomize",
        25,
        8,
        "dpmpp_2m_sde",
        "karras",
        1
      ]
    },
    {
      "id": 11,
      "type": "CLIPTextEncode",
      "pos": [
        344,
        229
      ],
      "size": [
        365.5308822298368,
        114.14346753367522
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            22,
            117
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "(background:1.4),ugly,monochrome ,lowres, bad anatomy, bad hands, text,missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, jpeg artifacts,mole"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 22,
      "type": "LoadImage",
      "pos": [
        743,
        -146
      ],
      "size": {
        "0": 314.5093078613281,
        "1": 499.5321350097656
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            133
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "00266-4210261446 (1).png",
        "image"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 3,
      "type": "IPAdapterModelLoader",
      "pos": [
        1576.946789916992,
        -45.34301754760733
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            126
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-full-face_sd15.safetensors"
      ]
    },
    {
      "id": 75,
      "type": "Image Rembg (Remove Background)",
      "pos": [
        1202.946789916992,
        -151.3430175476074
      ],
      "size": [
        300.48627818714476,
        250
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 133
        }
      ],
      "outputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "links": [
            134,
            135
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "Image Rembg (Remove Background)"
      },
      "widgets_values": [
        false,
        "u2net",
        false,
        false,
        false,
        240,
        10,
        10,
        "white"
      ]
    },
    {
      "id": 76,
      "type": "PreviewImage",
      "pos": [
        1214.946789916992,
        145.65698245239227
      ],
      "size": [
        210,
        246
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 135
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 70,
      "type": "Note",
      "pos": [
        444,
        472
      ],
      "size": {
        "0": 235.62548828125,
        "1": 128.09716796875
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "下載這個Lora模型\nPlease download this Lora\n\nhttps://civitai.com/models/55504/character-a-poses-vtuber-reference-pose-fullbody-halfbody"
      ],
      "color": "#2a363b",
      "bgcolor": "#3f5159"
    },
    {
      "id": 64,
      "type": "FaceDetailer",
      "pos": [
        2422,
        -131
      ],
      "size": {
        "0": 337.6000061035156,
        "1": 880
      },
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 111
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 129
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 114
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 115
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 116,
          "slot_index": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 117,
          "slot_index": 5
        },
        {
          "name": "bbox_detector",
          "type": "BBOX_DETECTOR",
          "link": 130
        },
        {
          "name": "sam_model_opt",
          "type": "SAM_MODEL",
          "link": null
        },
        {
          "name": "segm_detector_opt",
          "type": "SEGM_DETECTOR",
          "link": null
        },
        {
          "name": "detailer_hook",
          "type": "DETAILER_HOOK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "links": [
            110,
            131
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "cropped_refined",
          "type": "IMAGE",
          "links": null,
          "shape": 6
        },
        {
          "name": "cropped_enhanced_alpha",
          "type": "IMAGE",
          "links": null,
          "shape": 6
        },
        {
          "name": "mask",
          "type": "MASK",
          "links": null,
          "shape": 3
        },
        {
          "name": "detailer_pipe",
          "type": "DETAILER_PIPE",
          "links": null,
          "shape": 3
        },
        {
          "name": "cnet_images",
          "type": "IMAGE",
          "links": null,
          "shape": 6
        }
      ],
      "properties": {
        "Node name for S&R": "FaceDetailer"
      },
      "widgets_values": [
        256,
        true,
        768,
        961687353363341,
        "randomize",
        22,
        5,
        "dpmpp_2m_sde",
        "karras",
        0.5,
        5,
        true,
        true,
        0.5,
        10,
        3,
        "center-1",
        0,
        0.93,
        0,
        0.7,
        "False",
        10,
        "",
        1,
        false,
        10
      ]
    },
    {
      "id": 73,
      "type": "Image Rembg (Remove Background)",
      "pos": [
        2788,
        -141
      ],
      "size": {
        "0": 315,
        "1": 250
      },
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 131
        }
      ],
      "outputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "links": [
            132
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "Image Rembg (Remove Background)"
      },
      "widgets_values": [
        true,
        "isnet-anime",
        false,
        false,
        false,
        240,
        10,
        10,
        "none"
      ]
    },
    {
      "id": 72,
      "type": "UltralyticsDetectorProvider",
      "pos": [
        2800,
        161
      ],
      "size": {
        "0": 315,
        "1": 78
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "outputs": [
        {
          "name": "BBOX_DETECTOR",
          "type": "BBOX_DETECTOR",
          "links": [
            130
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "SEGM_DETECTOR",
          "type": "SEGM_DETECTOR",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "UltralyticsDetectorProvider"
      },
      "widgets_values": [
        "bbox/face_yolov8m.pt"
      ]
    },
    {
      "id": 69,
      "type": "IPAdapterApply",
      "pos": [
        1586.946789916992,
        74.6569824523925
      ],
      "size": {
        "0": 315,
        "1": 258
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 126
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 124
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 134
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 125,
          "slot_index": 3
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            128
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        1,
        1,
        "original",
        0,
        1,
        false
      ]
    },
    {
      "id": 10,
      "type": "CLIPTextEncode",
      "pos": [
        344.4093948697726,
        17.931666743668266
      ],
      "size": [
        370.5308822298368,
        157.7192066139311
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 46
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            36,
            116
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "masterpiece, best quality, Full body, vtuber-fullbody, ultra-detailed,(simple background), standing pose, A pose, looking at viewer, smile, Alignment\n"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 74,
      "type": "SaveImage",
      "pos": [
        3215,
        -401
      ],
      "size": [
        603.3388745117188,
        1169.9868298339845
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 132
        }
      ],
      "properties": {},
      "widgets_values": [
        "%date:yyyy-MM-dd%/ecjojo"
      ]
    },
    {
      "id": 42,
      "type": "SaveImage",
      "pos": [
        2814,
        295
      ],
      "size": [
        289.98538818359384,
        436.32370300292973
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 110
        }
      ],
      "properties": {},
      "widgets_values": [
        "%date:yyyy-MM-dd%/ecjojo"
      ]
    },
    {
      "id": 77,
      "type": "Note",
      "pos": [
        -27,
        32
      ],
      "size": [
        327.7999278137207,
        341.32154045410164
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "ComfyUI Workflow Templates \n@ecjojo\n\n⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯\nPatreon | ComfyUI Guide & Workflow\nhttps://www.patreon.com/ecjojo\n\nbuy me a coffee\nhttps://www.buymeacoffee.com/ecjojo\n\nFollow me on Twitter\nhttps://twitter.com/ecjojo_ai\n\nJoin my Discord Community\nhttps://discord.gg/mwVwW8j7Gy"
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 35,
      "type": "LoraLoader",
      "pos": [
        759,
        490
      ],
      "size": {
        "0": 315,
        "1": 126
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 128
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 45
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            48
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            46
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "vtuber-poses-05.safetensors",
        1,
        1
      ]
    }
  ],
  "links": [
    [
      13,
      2,
      1,
      11,
      0,
      "CLIP"
    ],
    [
      22,
      11,
      0,
      18,
      2,
      "CONDITIONING"
    ],
    [
      30,
      18,
      0,
      23,
      0,
      "LATENT"
    ],
    [
      32,
      2,
      2,
      23,
      1,
      "VAE"
    ],
    [
      34,
      26,
      0,
      18,
      3,
      "LATENT"
    ],
    [
      36,
      10,
      0,
      18,
      1,
      "CONDITIONING"
    ],
    [
      45,
      2,
      1,
      35,
      1,
      "CLIP"
    ],
    [
      46,
      35,
      1,
      10,
      0,
      "CLIP"
    ],
    [
      48,
      35,
      0,
      18,
      0,
      "MODEL"
    ],
    [
      110,
      64,
      0,
      42,
      0,
      "IMAGE"
    ],
    [
      111,
      23,
      0,
      64,
      0,
      "IMAGE"
    ],
    [
      114,
      2,
      1,
      64,
      2,
      "CLIP"
    ],
    [
      115,
      2,
      2,
      64,
      3,
      "VAE"
    ],
    [
      116,
      10,
      0,
      64,
      4,
      "CONDITIONING"
    ],
    [
      117,
      11,
      0,
      64,
      5,
      "CONDITIONING"
    ],
    [
      124,
      5,
      0,
      69,
      1,
      "CLIP_VISION"
    ],
    [
      125,
      2,
      0,
      69,
      3,
      "MODEL"
    ],
    [
      126,
      3,
      0,
      69,
      0,
      "IPADAPTER"
    ],
    [
      128,
      69,
      0,
      35,
      0,
      "MODEL"
    ],
    [
      129,
      2,
      0,
      64,
      1,
      "MODEL"
    ],
    [
      130,
      72,
      0,
      64,
      6,
      "BBOX_DETECTOR"
    ],
    [
      131,
      64,
      0,
      73,
      0,
      "IMAGE"
    ],
    [
      132,
      73,
      0,
      74,
      0,
      "IMAGE"
    ],
    [
      133,
      22,
      0,
      75,
      0,
      "IMAGE"
    ],
    [
      134,
      75,
      0,
      69,
      2,
      "IMAGE"
    ],
    [
      135,
      75,
      0,
      76,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "title": "IPA",
      "bounding": [
        1145,
        -236,
        803,
        675
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "FaceDetailer",
      "bounding": [
        2388,
        -232,
        775,
        1001
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Image Setting",
      "bounding": [
        1976,
        -233,
        373,
        675
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "FullbodyLora",
      "bounding": [
        735,
        401,
        359,
        248
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Prompt & Input Image",
      "bounding": [
        324,
        -243,
        779,
        618
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    }
  ],
  "config": {},
  "extra": {},
  "version": 0.4
}