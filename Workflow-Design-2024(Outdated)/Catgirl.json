{
  "last_node_id": 112,
  "last_link_id": 154,
  "nodes": [
    {
      "id": 35,
      "type": "LoraLoader",
      "pos": [
        36,
        252
      ],
      "size": {
        "0": 338.19451904296875,
        "1": 126
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 63
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 64
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            117
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            66,
            67
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "LCM_LoRA_Weights_SD15.safetensors",
        0.5,
        0.5
      ]
    },
    {
      "id": 38,
      "type": "VAELoader",
      "pos": [
        44,
        439
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            153
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "vae-ft-mse-840000-ema-pruned.safetensors"
      ]
    },
    {
      "id": 89,
      "type": "VAEDecode",
      "pos": [
        912.0335498046877,
        639.8890774154663
      ],
      "size": {
        "0": 210,
        "1": 46
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 110
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 153
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            149
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 110,
      "type": "Note",
      "pos": [
        -341,
        60
      ],
      "size": {
        "0": 337.9920654296875,
        "1": 425.6473083496094
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "Draw to Image Template\n\n\n⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯\nPatreon | ComfyUI Guide & Workflow\nhttps://www.patreon.com/ecjojo\n\nFollow me on Twitter\nhttps://twitter.com/ecjojo_ai\n\nJoin my Discord Community\nhttps://discord.gg/7cDb4vSH3z"
      ],
      "color": "#2a363b",
      "bgcolor": "#3f5159"
    },
    {
      "id": 107,
      "type": "SaveImage",
      "pos": [
        1235.0110815429687,
        114.37775764465331
      ],
      "size": {
        "0": 551.2574462890625,
        "1": 711.107177734375
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 149
        }
      ],
      "properties": {},
      "widgets_values": [
        "%date:yyyy-MM-dd%/Draw2Img"
      ]
    },
    {
      "id": 88,
      "type": "KSampler",
      "pos": [
        816,
        112
      ],
      "size": {
        "0": 315,
        "1": 474
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 117
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 154
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 108
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 115
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            110
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        226310008255615,
        "randomize",
        10,
        1.5,
        "lcm",
        "normal",
        1
      ]
    },
    {
      "id": 20,
      "type": "CheckpointLoaderSimple",
      "pos": [
        34,
        102
      ],
      "size": {
        "0": 343.69647216796875,
        "1": 98
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            63
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            64
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [],
          "shape": 3,
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "dreamshaper_8.safetensors"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        431,
        475
      ],
      "size": {
        "0": 295.4659423828125,
        "1": 276.84234619140625
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 67
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            108
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "embedding:EasyNegative, \nembedding:badhandv4, \nembedding:negative_hand-neg, \nworst quality, normal quality, low quality, monochrome, (nsfw), cat, Glasses,(ear)"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        55.01421922454835,
        641.622464282227
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            115
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        824,
        384,
        1
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        432,
        112
      ],
      "size": {
        "0": 305.80389404296875,
        "1": 315.0643005371094
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 66,
          "slot_index": 0
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            154
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "white cat ear girl, anime style, solo, cute, sweet, jk, big eye, bangs, blue eye, white hair, BLUE SKY, teen, upper body, smile, long hair, school girl"
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      63,
      20,
      0,
      35,
      0,
      "MODEL"
    ],
    [
      64,
      20,
      1,
      35,
      1,
      "CLIP"
    ],
    [
      66,
      35,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      67,
      35,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      108,
      7,
      0,
      88,
      2,
      "CONDITIONING"
    ],
    [
      110,
      88,
      0,
      89,
      0,
      "LATENT"
    ],
    [
      115,
      5,
      0,
      88,
      3,
      "LATENT"
    ],
    [
      117,
      35,
      0,
      88,
      0,
      "MODEL"
    ],
    [
      149,
      89,
      0,
      107,
      0,
      "IMAGE"
    ],
    [
      153,
      38,
      0,
      89,
      1,
      "VAE"
    ],
    [
      154,
      6,
      0,
      88,
      1,
      "CONDITIONING"
    ]
  ],
  "groups": [
    {
      "title": "Checkpoint & Lora Model",
      "bounding": [
        23,
        20,
        371,
        506
      ],
      "color": "#8AA",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Image Size",
      "bounding": [
        28,
        545,
        370,
        230
      ],
      "color": "#8AA",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "KSamlper",
      "bounding": [
        784,
        16,
        371,
        690
      ],
      "color": "#8AA",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Enter Prompt",
      "bounding": [
        409,
        19,
        347,
        760
      ],
      "color": "#8AA",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Save Image",
      "bounding": [
        1185,
        19,
        619,
        828
      ],
      "color": "#8AA",
      "font_size": 24,
      "locked": false
    }
  ],
  "config": {},
  "extra": {},
  "version": 0.4
}