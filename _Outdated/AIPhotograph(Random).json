{"last_node_id": 90, "last_link_id": 128, "nodes": [{"id": 77, "type": "EmptyLatentImage", "pos": [780, 80], "size": {"0": 315, "1": 106}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [87], "shape": 3}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [512, 512, 1]}, {"id": 18, "type": "EmptyLatentImage", "pos": [1490, 70], "size": {"0": 315, "1": 106}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [76], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [768, 1024, 1]}, {"id": 86, "type": "UltralyticsDetectorProvider", "pos": [1320, 1030], "size": {"0": 315, "1": 78}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "BBOX_DETECTOR", "type": "BBOX_DETECTOR", "links": [115], "shape": 3}, {"name": "SEGM_DETECTOR", "type": "SEGM_DETECTOR", "links": null, "shape": 3}], "properties": {"Node name for S&R": "UltralyticsDetectorProvider"}, "widgets_values": ["bbox/face_yolov8m.pt"]}, {"id": 2, "type": "CheckpointLoaderSimple", "pos": [440, 1040], "size": {"0": 315, "1": 98}, "flags": {}, "order": 3, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [116], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [85, 117], "shape": 3, "slot_index": 1}, {"name": "VAE", "type": "VAE", "links": null, "shape": 3}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["yabalMixSemireal_v1.safetensors"]}, {"id": 16, "type": "VAELoader", "pos": [440, 1350], "size": {"0": 312.9195861816406, "1": 63.224971771240234}, "flags": {}, "order": 4, "mode": 0, "outputs": [{"name": "VAE", "type": "VAE", "links": [17, 45, 82], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["vae-ft-mse-840000-ema-pruned.safetensors"]}, {"id": 52, "type": "IPAdapterModelLoader", "pos": [1900, 0], "size": {"0": 315, "1": 58}, "flags": {}, "order": 5, "mode": 0, "outputs": [{"name": "IPADAPTER", "type": "IPADAPTER", "links": [69], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "IPAdapterModelLoader"}, "widgets_values": ["ip-adapter-plus_sd15.bin"]}, {"id": 66, "type": "CLIPVisionLoader", "pos": [1900, 110], "size": {"0": 315, "1": 58}, "flags": {"collapsed": false}, "order": 6, "mode": 0, "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "links": [74], "shape": 3}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["model.safetensors"]}, {"id": 3, "type": "KSampler", "pos": [1500, 220], "size": {"0": 316.31097412109375, "1": 282}, "flags": {}, "order": 20, "mode": 3, "inputs": [{"name": "model", "type": "MODEL", "link": 127}, {"name": "positive", "type": "CONDITIONING", "link": 63, "slot_index": 1}, {"name": "negative", "type": "CONDITIONING", "link": 20, "slot_index": 2}, {"name": "latent_image", "type": "LATENT", "link": 76, "slot_index": 3}, {"name": "onTrigger", "type": -1, "link": null, "optional": true, "nameLocked": true}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [68], "shape": 3, "slot_index": 0}, {"name": "onExecuted", "type": -1, "links": null, "optional": true, "nameLocked": true}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [1090860508940071, "randomize", 10, 1.5, "lcm", "exponential", 1]}, {"id": 74, "type": "KSampler", "pos": [770, 250], "size": {"0": 315, "1": 262}, "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 120, "slot_index": 0}, {"name": "positive", "type": "CONDITIONING", "link": 78}, {"name": "negative", "type": "CONDITIONING", "link": 86, "slot_index": 2}, {"name": "latent_image", "type": "LATENT", "link": 87, "slot_index": 3}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [79], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [341331768190645, "randomize", 10, 1.5, "lcm", "exponential", 1]}, {"id": 42, "type": "FaceDetailer", "pos": [1310, 1160], "size": {"0": 337.6000061035156, "1": 832}, "flags": {}, "order": 23, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 42}, {"name": "model", "type": "MODEL", "link": 43}, {"name": "clip", "type": "CLIP", "link": 44, "slot_index": 2}, {"name": "vae", "type": "VAE", "link": 45, "slot_index": 3}, {"name": "positive", "type": "CONDITIONING", "link": 62, "slot_index": 4}, {"name": "negative", "type": "CONDITIONING", "link": 47, "slot_index": 5}, {"name": "bbox_detector", "type": "BBOX_DETECTOR", "link": 115, "slot_index": 6}, {"name": "sam_model_opt", "type": "SAM_MODEL", "link": null}, {"name": "segm_detector_opt", "type": "SEGM_DETECTOR", "link": null}, {"name": "detailer_hook", "type": "DETAILER_HOOK", "link": null}], "outputs": [{"name": "image", "type": "IMAGE", "links": [50], "shape": 3, "slot_index": 0}, {"name": "cropped_refined", "type": "IMAGE", "links": null, "shape": 6}, {"name": "cropped_enhanced_alpha", "type": "IMAGE", "links": null, "shape": 6}, {"name": "mask", "type": "MASK", "links": null, "shape": 3}, {"name": "detailer_pipe", "type": "DETAILER_PIPE", "links": null, "shape": 3}, {"name": "cnet_images", "type": "IMAGE", "links": null, "shape": 6}], "properties": {"Node name for S&R": "FaceDetailer"}, "widgets_values": [256, true, 768, 638224374713803, "randomize", 8, 1.5, "lcm", "exponential", 0.5, 5, true, true, 0.5, 10, 3, "center-1", 0, 0.93, 0, 0.7, "False", 10, "", 1]}, {"id": 55, "type": "Text to Conditioning", "pos": [1160, 570], "size": {"0": 315, "1": 58}, "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 61}, {"name": "text", "type": "STRING", "link": 51, "widget": {"name": "text"}}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [62, 63], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "Text to Conditioning"}, "widgets_values": [""], "color": "#232", "bgcolor": "#353"}, {"id": 73, "type": "Text to Conditioning", "pos": [420, 570], "size": {"0": 315, "1": 58}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 85, "slot_index": 0}, {"name": "text", "type": "STRING", "link": 77, "widget": {"name": "text"}}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [78], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "Text to Conditioning"}, "widgets_values": [""], "color": "#232", "bgcolor": "#353"}, {"id": 7, "type": "OneButtonPrompt", "pos": [1150, 90], "size": [320.55535888671875, 410], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "custom_subject", "type": "STRING", "link": 123, "widget": {"name": "custom_subject"}, "slot_index": 0}], "outputs": [{"name": "prompt", "type": "STRING", "links": [51], "shape": 3, "slot_index": 0}, {"name": "prompt_g", "type": "STRING", "links": null, "shape": 3}, {"name": "prompt_l", "type": "STRING", "links": null, "shape": 3}], "properties": {"Node name for S&R": "OneButtonPrompt"}, "widgets_values": [5, "photography", "portrait", 25, "humanoid", "masterpiece, best quality, solo,1girl,dark hair, long hair, brown eyes, hair bangs ,cute, shiny skin,elf ear,outdoor,standing pose,white skin,detailed face,dress", "", "all", "generic humans", "female", "all", false, 962386478669260, "randomize"], "color": "#232", "bgcolor": "#353"}, {"id": 19, "type": "CLIPTextEncode", "pos": [460, 1490], "size": {"0": 292.05694580078125, "1": 163.67738342285156}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 21, "slot_index": 0}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [20, 47, 86], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["embedding:easynegative, embedding:badhandv4, nsfw, cat ear,big ear, big face,dark skin,black color,simple background,fat,very long hair,watermark,name,text, worst quality"], "color": "#322", "bgcolor": "#533"}, {"id": 15, "type": "VAEDecode", "pos": [1500, 570], "size": {"0": 304.6690368652344, "1": 53.796607971191406}, "flags": {}, "order": 21, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 68}, {"name": "vae", "type": "VAE", "link": 17, "slot_index": 1}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [18, 42], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 53, "type": "SaveImage", "pos": [1750, 1040], "size": [296.5341033935538, 337.90291137695226], "flags": {}, "order": 24, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 50}], "properties": {}, "widgets_values": ["AIPhoto(Random)/image"]}, {"id": 87, "type": "LoraLoader", "pos": [440, 1180], "size": {"0": 315, "1": 126}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 116}, {"name": "clip", "type": "CLIP", "link": 117}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [120, 122, 126], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [119], "shape": 3, "slot_index": 1}], "properties": {"Node name for S&R": "LoraLoader"}, "widgets_values": ["LCM_LoRA_Weights_SD15.safetensors", 1, 1]}, {"id": 63, "type": "IPAdapterApply", "pos": [1910, 220], "size": {"0": 298.37408447265625, "1": 278}, "flags": {"collapsed": false}, "order": 17, "mode": 0, "inputs": [{"name": "ipadapter", "type": "IPADAPTER", "link": 69}, {"name": "clip_vision", "type": "CLIP_VISION", "link": 74, "slot_index": 1}, {"name": "image", "type": "IMAGE", "link": 80, "slot_index": 2}, {"name": "model", "type": "MODEL", "link": 122, "slot_index": 3}, {"name": "onTrigger", "type": -1, "link": null, "optional": true, "nameLocked": true}, {"name": "insightface", "type": "INSIGHTFACE", "link": null}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [109], "shape": 3, "slot_index": 0}, {"name": "onExecuted", "type": -1, "links": null, "optional": true, "nameLocked": true, "slot_index": 1}], "title": "Apply IPAdapter (Background)", "properties": {"Node name for S&R": "IPAdapterApply"}, "widgets_values": [0.5, 0.5, "original", 0, 1, false]}, {"id": 82, "type": "ModelMergeSimple", "pos": [1910, 560], "size": {"0": 315, "1": 78}, "flags": {}, "order": 19, "mode": 0, "inputs": [{"name": "model1", "type": "MODEL", "link": 109, "slot_index": 0}, {"name": "model2", "type": "MODEL", "link": 110, "slot_index": 1}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [127], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ModelMergeSimple"}, "widgets_values": [1]}, {"id": 75, "type": "VAEDecode", "pos": [770, 570], "size": {"0": 307.4527282714844, "1": 46}, "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 79}, {"name": "vae", "type": "VAE", "link": 82}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [80, 128], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 89, "type": "PreviewImage", "pos": [870, 670], "size": [210, 246], "flags": {}, "order": 18, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 128}], "properties": {"Node name for S&R": "PreviewImage"}}, {"id": 17, "type": "PreviewImage", "pos": [1630, 680], "size": [167.17640686035156, 246], "flags": {}, "order": 22, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 18}], "properties": {"Node name for S&R": "PreviewImage"}}, {"id": 90, "type": "Note", "pos": [2110, 990], "size": {"0": 431.6261291503906, "1": 292.80670166015625}, "flags": {}, "order": 9, "mode": 0, "properties": {"text": ""}, "widgets_values": ["\u9019\u500bWorkflow\u53ef\u4ee5\u751f\u6210\u651d\u5f71\u68da\u89d2\u8272+AI\u7f6e\u666f, \u4e5f\u52a0\u5165\u4f60\u7684\u81ea\u5df1\u7684\u89d2\u8272.\n\u81ea\u5df1\u8abf\u6574\u53c3\u6578\u548cPrompt\u4f86\u9054\u5230\u4f60\u9700\u8981\u7684\u6548\u679c~\n\nThis Template can using your photo or gen a model and change background.\n\n\n\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\nPatreon | ComfyUI Guide & Workflow\nhttps://www.patreon.com/ecjojo\n\nFollow me on Twitter\nhttps://twitter.com/ecjojo_ai\n\nJoin my Discord Community\nhttps://discord.gg/7cDb4vSH3z"], "color": "#323", "bgcolor": "#535"}, {"id": 1, "type": "LoraLoader", "pos": [880, 1040], "size": {"0": 320.023681640625, "1": 151.27076721191406}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 126, "slot_index": 0}, {"name": "clip", "type": "CLIP", "link": 119}, {"name": "onTrigger", "type": -1, "link": null, "optional": true, "nameLocked": true, "slot_index": 2}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [43, 110], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [21, 44, 61], "shape": 3, "slot_index": 1}, {"name": "onExecuted", "type": -1, "links": null, "optional": true, "nameLocked": true, "slot_index": 2}], "properties": {"Node name for S&R": "LoraLoader"}, "widgets_values": ["EC.safetensors", 0.6, 0.6]}, {"id": 88, "type": "CR Prompt Text", "pos": [1160, -260], "size": {"0": 400, "1": 200}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "prompt", "type": "STRING", "links": [123], "shape": 3, "slot_index": 0}, {"name": "show_help", "type": "STRING", "links": null, "shape": 3}], "properties": {"Node name for S&R": "CR Prompt Text"}, "widgets_values": ["masterpiece, best quality, solo, 1girl,dark hair, long hair, brown eyes, hair bangs ,cute, shiny skin, elf ear,outdoor,standing pose,white skin,detailed face,dress"], "color": "#232", "bgcolor": "#353"}, {"id": 71, "type": "OneButtonPrompt", "pos": [420, 90], "size": {"0": 314.730712890625, "1": 410}, "flags": {}, "order": 8, "mode": 0, "outputs": [{"name": "prompt", "type": "STRING", "links": [77], "shape": 3, "slot_index": 0}, {"name": "prompt_g", "type": "STRING", "links": null, "shape": 3}, {"name": "prompt_l", "type": "STRING", "links": null, "shape": 3}], "properties": {"Node name for S&R": "OneButtonPrompt"}, "widgets_values": [10, "landscape", "digital art", 25, "landscape", "background", "", "all", "all", "all", "all", false, 155383381678954, "randomize"], "color": "#232", "bgcolor": "#353"}], "links": [[17, 16, 0, 15, 1, "VAE"], [18, 15, 0, 17, 0, "IMAGE"], [20, 19, 0, 3, 2, "CONDITIONING"], [21, 1, 1, 19, 0, "CLIP"], [42, 15, 0, 42, 0, "IMAGE"], [43, 1, 0, 42, 1, "MODEL"], [44, 1, 1, 42, 2, "CLIP"], [45, 16, 0, 42, 3, "VAE"], [47, 19, 0, 42, 5, "CONDITIONING"], [50, 42, 0, 53, 0, "IMAGE"], [51, 7, 0, 55, 1, "STRING"], [61, 1, 1, 55, 0, "CLIP"], [62, 55, 0, 42, 4, "CONDITIONING"], [63, 55, 0, 3, 1, "CONDITIONING"], [68, 3, 0, 15, 0, "LATENT"], [69, 52, 0, 63, 0, "IPADAPTER"], [74, 66, 0, 63, 1, "CLIP_VISION"], [76, 18, 0, 3, 3, "LATENT"], [77, 71, 0, 73, 1, "STRING"], [78, 73, 0, 74, 1, "CONDITIONING"], [79, 74, 0, 75, 0, "LATENT"], [80, 75, 0, 63, 2, "IMAGE"], [82, 16, 0, 75, 1, "VAE"], [85, 2, 1, 73, 0, "CLIP"], [86, 19, 0, 74, 2, "CONDITIONING"], [87, 77, 0, 74, 3, "LATENT"], [109, 63, 0, 82, 0, "MODEL"], [110, 1, 0, 82, 1, "MODEL"], [115, 86, 0, 42, 6, "BBOX_DETECTOR"], [116, 2, 0, 87, 0, "MODEL"], [117, 2, 1, 87, 1, "CLIP"], [119, 87, 1, 1, 1, "CLIP"], [120, 87, 0, 74, 0, "MODEL"], [122, 87, 0, 63, 3, "MODEL"], [123, 88, 0, 7, 0, "STRING"], [126, 87, 0, 1, 0, "MODEL"], [127, 82, 0, 3, 0, "MODEL"], [128, 75, 0, 89, 0, "IMAGE"]], "groups": [{"title": "Character Lora", "bounding": [852, 956, 412, 255], "color": "#b58b2a", "font_size": 24, "locked": false}, {"title": "Base Style", "bounding": [418, 953, 372, 744], "color": "#3f789e", "font_size": 24, "locked": false}, {"title": "Random Background Setting", "bounding": [363, -8, 735, 672], "color": "#3f789e", "font_size": 24, "locked": false}, {"title": "Random Character Setting", "bounding": [1127, -5, 699, 666], "color": "#3f789e", "font_size": 24, "locked": false}, {"title": "ImageMerge", "bounding": [1860, -83, 404, 743], "color": "#3f789e", "font_size": 24, "locked": false}, {"title": "Character Face Detector", "bounding": [1289, 960, 408, 1044], "color": "#b58b2a", "font_size": 24, "locked": false}, {"title": "Result", "bounding": [1723, 968, 363, 462], "color": "#b58b2a", "font_size": 24, "locked": false}], "config": {}, "extra": {}, "version": 0.4}